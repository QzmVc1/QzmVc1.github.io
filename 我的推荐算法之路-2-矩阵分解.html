<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/favicon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon.png">
  <link rel="mask-icon" href="/images/favicon.png" color="#222">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Serif+SC:300,300italic,400,400italic,700,700italic%7CRoboto+Mono:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">


<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/animate.css@3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/themes/blue/pace-theme-fill-left.css">
  <script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js" integrity="sha256-gqd7YTjg/BtfqWSwsJOvndl0Bxc8gFImLEkXQT8+qj0=" crossorigin="anonymous"></script>

<script class="next-config" data-name="main" type="application/json">{"hostname":"qzmvc1.top","root":"/","images":"/images","scheme":"Gemini","darkmode":false,"version":"8.8.0","exturl":false,"sidebar":{"position":"left","width":310,"display":"post","padding":18,"offset":12},"copycode":true,"bookmark":{"enable":true,"color":"#222","save":"manual"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":"utterances","storage":true,"lazyload":false,"nav":null,"activeClass":"utterances"},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js"></script>


<meta name="description" content="前言针对协同过滤算法的头部效应较明显、泛化能力较弱的问题，矩阵分解算法被提出。矩阵分解在协同过滤算法中“共现矩阵”的基础上，加入了隐向量的概念，加强了模型处理稀疏矩阵的能力，针对性地解决了协同过滤存在的主要问题。">
<meta property="og:type" content="article">
<meta property="og:title" content="我的推荐算法之路(2):矩阵分解">
<meta property="og:url" content="http://qzmvc1.top/%E6%88%91%E7%9A%84%E6%8E%A8%E8%8D%90%E7%AE%97%E6%B3%95%E4%B9%8B%E8%B7%AF-2-%E7%9F%A9%E9%98%B5%E5%88%86%E8%A7%A3.html">
<meta property="og:site_name" content="QzmVc1">
<meta property="og:description" content="前言针对协同过滤算法的头部效应较明显、泛化能力较弱的问题，矩阵分解算法被提出。矩阵分解在协同过滤算法中“共现矩阵”的基础上，加入了隐向量的概念，加强了模型处理稀疏矩阵的能力，针对性地解决了协同过滤存在的主要问题。">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://z3.ax1x.com/2021/07/31/Wj2vge.png">
<meta property="og:image" content="https://z3.ax1x.com/2021/07/31/WjRr8O.png">
<meta property="article:published_time" content="2021-07-31T06:03:28.000Z">
<meta property="article:modified_time" content="2021-10-06T11:49:50.000Z">
<meta property="article:author" content="QzmVc1">
<meta property="article:tag" content="推荐算法">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://z3.ax1x.com/2021/07/31/Wj2vge.png">


<link rel="canonical" href="http://qzmvc1.top/%E6%88%91%E7%9A%84%E6%8E%A8%E8%8D%90%E7%AE%97%E6%B3%95%E4%B9%8B%E8%B7%AF-2-%E7%9F%A9%E9%98%B5%E5%88%86%E8%A7%A3.html">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"http://qzmvc1.top/%E6%88%91%E7%9A%84%E6%8E%A8%E8%8D%90%E7%AE%97%E6%B3%95%E4%B9%8B%E8%B7%AF-2-%E7%9F%A9%E9%98%B5%E5%88%86%E8%A7%A3.html","path":"我的推荐算法之路-2-矩阵分解.html","title":"我的推荐算法之路(2):矩阵分解"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>

<script>
    (function(){
        if(''){
            if (prompt('加密文，来试试你的运气吧！') !== ''){
                alert('要不要再尝试一次呢~~');
                history.back();
            }
        }
    })();
</script><title>我的推荐算法之路(2):矩阵分解 | QzmVc1</title>
  




  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">QzmVc1</h1>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">Standing on Shoulders of Giants.</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu">
        <li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li>
        <li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li>
        <li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li>
        <li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</div>
        
  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%89%8D%E8%A8%80"><span class="nav-text">前言</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%80%E3%80%81%E7%9F%A9%E9%98%B5%E5%88%86%E8%A7%A3"><span class="nav-text">一、矩阵分解</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BA%8C%E3%80%81%E7%9F%A9%E9%98%B5%E5%88%86%E8%A7%A3%E7%9A%84%E4%BC%98%E7%BC%BA%E7%82%B9"><span class="nav-text">二、矩阵分解的优缺点</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%89%E3%80%81%E7%9F%A9%E9%98%B5%E5%88%86%E8%A7%A3%E7%9B%B8%E5%85%B3%E7%AE%97%E6%B3%95"><span class="nav-text">三、矩阵分解相关算法</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#3-1-%E5%A5%87%E5%BC%82%E5%80%BC%E5%88%86%E8%A7%A3SVD"><span class="nav-text">3.1 奇异值分解SVD</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-2-Funk-SVD"><span class="nav-text">3.2 Funk-SVD</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-3-Bias-SVD"><span class="nav-text">3.3 Bias-SVD</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9B%9B%E3%80%81%E5%9F%BA%E4%BA%8EPytorch%E7%9A%84%E7%9F%A9%E9%98%B5%E5%88%86%E8%A7%A3"><span class="nav-text">四、基于Pytorch的矩阵分解</span></a></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="QzmVc1"
      src="/images/touxiang.jpg">
  <p class="site-author-name" itemprop="name">QzmVc1</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">83</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">9</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">40</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author site-overview-item animated">
      <span class="links-of-author-item">
        <a href="mailto:qzmvc1@gmail.com" title="E-Mail → mailto:qzmvc1@gmail.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>


  <div class="links-of-blogroll site-overview-item animated">
    <div class="links-of-blogroll-title"><i class="fa fa-globe fa-fw"></i>
      友情链接
    </div>
    <ul class="links-of-blogroll-list">
        <li class="links-of-blogroll-item">
          <a href="https://jcoffeezph.top/" title="https:&#x2F;&#x2F;jcoffeezph.top&#x2F;" rel="noopener" target="_blank">ForMe</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://szd0319.github.io/" title="https:&#x2F;&#x2F;szd0319.github.io&#x2F;" rel="noopener" target="_blank">Silence</a>
        </li>
    </ul>
  </div>

        </div>
      </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>
  <a role="button" class="book-mark-link book-mark-link-fixed"></a>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://qzmvc1.top/%E6%88%91%E7%9A%84%E6%8E%A8%E8%8D%90%E7%AE%97%E6%B3%95%E4%B9%8B%E8%B7%AF-2-%E7%9F%A9%E9%98%B5%E5%88%86%E8%A7%A3.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/touxiang.jpg">
      <meta itemprop="name" content="QzmVc1">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="QzmVc1">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          我的推荐算法之路(2):矩阵分解
        </h1>

        <div class="post-meta-container">

          <div class="post-meta">
  
	
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2021-07-31 14:03:28" itemprop="dateCreated datePublished" datetime="2021-07-31T14:03:28+08:00">2021-07-31</time>
    </span>
      <span class="post-meta-item">
        <span class="post-meta-item-icon">
          <i class="far fa-calendar-check"></i>
        </span>
        <span class="post-meta-item-text">更新于</span>
        <time title="修改时间：2021-10-06 19:49:50" itemprop="dateModified" datetime="2021-10-06T19:49:50+08:00">2021-10-06</time>
      </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%8E%A8%E8%8D%90%E7%AE%97%E6%B3%95/" itemprop="url" rel="index"><span itemprop="name">推荐算法</span></a>
        </span>
    </span>

  
    <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv">
      <span class="post-meta-item-icon">
        <i class="far fa-eye"></i>
      </span>
      <span class="post-meta-item-text">阅读次数：</span>
      <span id="busuanzi_value_page_pv"></span>
    </span>
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>6.8k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>6 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p>针对协同过滤算法的头部效应较明显、泛化能力较弱的问题，矩阵分解算法被提出。矩阵分解在协同过滤算法中“共现矩阵”的基础上，加入了隐向量的概念，加强了模型处理稀疏矩阵的能力，针对性地解决了协同过滤存在的主要问题。</p>
<span id="more"></span>



<h3 id="一、矩阵分解"><a href="#一、矩阵分解" class="headerlink" title="一、矩阵分解"></a>一、矩阵分解</h3><p>矩阵分解有几个明显的特点，它具有协同过滤的 “集体智慧”，隐语义的 “深层关系”，以及机器学习的 “以目标为导向的有监督学习”。在了解了基于邻域的协同过滤算法后，集体智慧自不必多说，我们依次从 “隐因子” 和 “有监督学习” 的角度来了解矩阵分解的基本思路。</p>
<p>推荐算法中的矩阵分解最初的想法是从奇异值分解（Singular Value Decomposition，SVD）借鉴来的。以 $Netflix$ 用户对电影的评分矩阵为例，矩阵分解，直观上来说就是把原来的大矩阵，近似分解成两个小矩阵的乘积，在实际推荐计算时不再使用大矩阵，而是使用分解得到的两个小矩阵。按照矩阵分解的原理，我们会发现原来 $m×n$ 的大矩阵会分解成 $m×k$ 和 $k×n$ 的两个小矩阵，这里多出来一个 $k$ 维向量，就是隐因子向量（Latent Factor Vector）。$k$ 的大小决定了隐向量表达能力的强弱。 $k$ 的取值越小，隐向量包含的信息越少，模型的泛化程度越高；反之，$k$ 的取值越大，隐向量的表达能力越强，但泛化程度相应降低。此外，$k$ 的取值还与矩阵分解的求解复杂度直接相关。</p>
<p><img src="https://z3.ax1x.com/2021/07/31/Wj2vge.png"></p>
<p><strong>基于矩阵分解的推荐算法的核心假设是用隐向量来表达用户和物品，他们的乘积关系就成为了原始的元素。</strong>这种假设之所以成立，是因为我们认为实际的交互数据是由一系列的隐向量的影响下产生的，这些隐向量代表了用户和物品一部分共有的特征，在物品身上表现为属性特征，在用户身上表现为偏好特征，只不过这些因子并不具有实际意义，也不一定具有非常好的可解释性，每一个维度也没有确定的标签名字，所以才会叫做 “隐变量”。而矩阵分解后得到的两个包含隐变量的小矩阵，一个代表用户的隐含特征，一个代表物品的隐含特征，矩阵的元素值代表着相应用户或物品对各项隐因子的符合程度，有正面的也有负面的。</p>
<p>我们再从机器学习的角度来了解矩阵分解，<strong>我们已经知道评分预测实际上是一个矩阵补全的过程，在矩阵分解的时候原来的大矩阵必然是稀疏的，即有一部分有评分，有一部分是没有评分的，不然也就没必要预测和推荐了，所以整个预测模型的最终目的是得到两个小矩阵，通过这两个小矩阵的乘积来补全大矩阵中没有评分的位置。</strong>所以对于机器学习模型来说，<strong>问题转化成了如何获得两个最优的小矩阵</strong>。因为大矩阵有一部分是有评分的，那么只要保证大矩阵有评分的位置（实际值）与两个小矩阵相乘得到的相应位置的评分（预测值）之间的误差最小即可，其实就是一个均方误差损失，这便是模型的目标函数。</p>
<p><img src="https://z3.ax1x.com/2021/07/31/WjRr8O.png"></p>
<h3 id="二、矩阵分解的优缺点"><a href="#二、矩阵分解的优缺点" class="headerlink" title="二、矩阵分解的优缺点"></a>二、矩阵分解的优缺点</h3><blockquote>
<p><strong>矩阵分解具有以下优点：</strong></p>
<ul>
<li>泛化能力强。在一定程度上解决了数据稀疏的问题。</li>
<li>空间复杂度低。不需再存储协同过滤模型所需的“庞大“用户相似性或物品相似性矩阵，只需存储用户和物品隐向量空间复杂度由 $n^2$ 级别降低到 $(n+m)*k$ 级别。</li>
<li>更好的扩展性和灵活性。矩阵分解最终产出的是用户和物品隐向量，这其实与深度学习中的Embedding思想不谋而合，因此矩阵分解的结果也非常便于与其他特征进行组合和拼接，与深度学习网络进行无缝组合。</li>
</ul>
</blockquote>
<blockquote>
<p><strong>矩阵分解也有一些局限性：</strong></p>
<ul>
<li>矩阵分解不方便加入用户、物品、上下文相关的特征，丧失了利用很多有效信息的机会。</li>
<li>在缺乏用户历史行为时，无法进行有效的推荐。</li>
<li>模型训练比较费时。</li>
<li>推荐结果不具有很好的可解释性，分解出来的用户和物品矩阵的每个维度无法用现实生活中的概念来解释，只能理解为潜在语义空间。</li>
</ul>
</blockquote>
<h3 id="三、矩阵分解相关算法"><a href="#三、矩阵分解相关算法" class="headerlink" title="三、矩阵分解相关算法"></a>三、矩阵分解相关算法</h3><h4 id="3-1-奇异值分解SVD"><a href="#3-1-奇异值分解SVD" class="headerlink" title="3.1 奇异值分解SVD"></a>3.1 奇异值分解SVD</h4><p>有关SVD的原理阐述请参考我的相关博客：<a href="https://qzmvc1.top/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%97%A5%E8%AE%B0-%E5%9B%9B-%E5%A5%87%E5%BC%82%E5%80%BC%E5%88%86%E8%A7%A3.html">机器学习日记(四):奇异值分解</a></p>
<p>虽然奇异值分解解决了矩阵分解问题，但其存在两点缺陷，使其不宜作为互联网场景下矩阵分解的主要方法：</p>
<ul>
<li>SVD 要求矩阵是稠密的，而现实场景中的共现矩阵是稀疏的，有大量空白，无法直接使用 SVD 分解。要想使用 SVD，必须对评分矩阵中的缺失值进行简单的补全，比如用全局平均值或者用用户物品平均值补全，得到补全后的矩阵。接着可以用 SVD 分解并降维。但填充本身会造成很多问题，其一，填充大大增加了数据量，增加了算法复杂度。其二，简单粗暴的数据填充很容易造成数据失真。</li>
<li>传统奇异值分解的计算复杂度达到了 $O(mn^2)$ 的级别，这对于商品数量动辄上百万、用户数量往往上千万的互联网场景来说几乎是不可接受的。</li>
</ul>
<h4 id="3-2-Funk-SVD"><a href="#3-2-Funk-SVD" class="headerlink" title="3.2 Funk-SVD"></a>3.2 Funk-SVD</h4><p>$Simon　Funk$ 在博客上公开发表了一个只考虑已有评分记录的矩阵分解方法，称为 $Funk-SVD$，也就是被 $Yehuda Koren$ 称为隐语义模型的矩阵分解方法。它的出发点为，既然将一个矩阵做 SVD 分解成 3 个矩阵很耗时，同时还面临稀疏的问题，<strong>那么我们能不能避开稀疏问题，同时只分解成两个矩阵呢？</strong>也就是说，现在期望我们的矩阵$M$ 这样进行分解：<br>$$<br>M_{m×n}=P_{m×k}^TQ_{k×n}<br>$$<br><strong>这种简化的矩阵分解不再是分解为三个矩阵，而是分解为两个低秩的用户和物品矩阵，其实就是把用户和物品都映射到一个 $k$ 维空间中，</strong>这个 $k$ 维空间对应着 $k$ 个隐因子，我们认为用户对物品的评分主要是由这些隐因子影响的，所以这些隐因子代表了用户和物品一部分共有的特征，在物品身上表现为属性特征，在用户身上表现为偏好特征。只不过这些隐因子并不具有实际意义，也不一定具有非常好的可解释性，每一个维度也没有确定的标签名字，所以才会叫做 “隐因子”。</p>
<p>我们知道 $SVD$ 分解已经很成熟了，但是 $Funk-SVD$ 如何将矩阵 $M$ 分解成为 $P$ 和 $Q$ 呢？<strong>这里采用了线性回归的思想。我们的目标是让用户的评分和用矩阵乘积得到的评分残差尽可能的小</strong>，也就是说，可以用均方差作为损失函数，来寻找最终的P和Q。即通过 User-Item 评分信息来学习到的用户特征矩阵 $P$ 和物品特征矩阵 $Q$，通过重构的低维矩阵预测用户对物品的评分。</p>
<p>对于某一个用户评分 $m_{ij}$ 如果用 $Funk-SVD$ 进行矩阵分解，则对应的表示为 $q_j^Tp_i$，采用均方差作为损失函数，则我们期望 $(m_{ij}-q_j^Tp_i)^2$ 尽可能的小，如果考虑所有的物品和样本的组合，则我们期望最小化下式：<br>$$<br>\sum_{i,j}(m_{ij}-q_j^Tp_i)^2<br>$$<br>只要我们能够最小化上面的式子，并求出极值所对应的 $p_i,q_j$，则我们最终可以得到矩阵 $P$ 和 $Q$，那么对于任意矩阵 $M$ 任意一个空白评分的位置，我们可以通过 $q_j^Tp_i$ 计算预测评分，很漂亮的方法！</p>
<p>当然，在实际应用中，为了防止过拟合，会加入一个 $L2$ 的正则化项，因此正式的 $Funk-SVD$ 的优化目标函数是这样的：<br>$$<br>arg\mathop{min}\limits_{p_i,q_j}\sum_{(i,j)\in K}(m_{ij}-q_j^Tp_i)^2+\lambda(||p_i||^2_2+||q_j||^2_2)<br>$$<br>其中 $K$ 为已有评分记录的 $(i,j)$ 对集合，$m_{ij}$ 为用户 $i$ 对物品 $j$ 的真实评分，$\lambda$ 是正则化系数。对于这个优化问题，一般通过<strong>梯度下降法</strong>来进行优化得到结果。</p>
<p>将上式分别对 $p_i,q_j$ 求导：<br>$$<br>\frac{∂J}{∂p_i} = -2(m_{ij}-q_j^Tp_i)q_j+2\lambda p_i<br>$$</p>
<p>$$<br>\frac{∂J}{∂q_j} = -2(m_{ij}-q_j^Tp_i)p_i+2\lambda q_j<br>$$</p>
<p>则在梯度下降法迭代时，$p_i,q_j$ 的迭代公式为：<br>$$<br>p_i = p_i + \alpha ((m_{ij}-q_j^Tp_i)q_j-\lambda p_i)<br>$$</p>
<p>$$<br>q_j = q_j + \alpha ((m_{ij}-q_j^Tp_i)p_i-\lambda q_j)<br>$$</p>
<h4 id="3-3-Bias-SVD"><a href="#3-3-Bias-SVD" class="headerlink" title="3.3 Bias-SVD"></a>3.3 Bias-SVD</h4><p>在 $Funk-SVD$ 算法火爆之后，出现了很多 $Funk-SVD$ 的改进版算法。其中 $Bias$ 算是改进的比较成功的一种算法。其在 $Funk-SVD$ 的基础上加了偏置项特征。</p>
<p>由于不同用户的打分体系不同（比如在5分为满分的情况下，有的用户认为打3分已经是很低的分数了，而有的用户认为打1分才是比较差的评价），不同用户的衡量标准也有所区别（比如电子产品的平均分和日用品的平均分差异有可能比较大），为了消除用户和物品打分的偏差（Bias），常用的做法是在矩阵分解时加入用户和物品的偏差向量，如下所示：<br>$$<br>r_{ui} = \mu + b_i + b_u + q_j^Tp_i<br>$$<br>偏置部分主要由三个子部分组成：</p>
<ul>
<li>训练集中所有评分记录的全局平均数 $\mu$ ，表示了训练数据的总体评分情况，对于固定的数据集，它是一个常数。</li>
<li>用户偏置 $b_u$，独立于物品特征的因素，表示某一特定用户的打分习惯。例如，对于批判性用户对于自己的评分比较苛刻，倾向于打低分；而乐观型用户则打分比较保守，总体打分要偏高。</li>
<li>物品偏置 $b_i$ ，特立于用户兴趣的因素，表示某一特定物品得到的打分情况。以电影为例，好片获得的总体评分偏高，而烂片获得的评分普遍偏低，物品偏置捕获的就是这样的特征。</li>
</ul>
<p>加入了偏置项以后的优化目标函数如下所示：<br>$$<br>arg\mathop{min}\limits_{p_i,q_j}\sum_{(i,j)\in K}(m_{ij}-q_j^Tp_i-\mu-b_i-b_u)^2+\lambda(||p_i||^2_2+||q_j||^2_2+||b_i||^2_2+||b_u||^2_2)<br>$$</p>
<h3 id="四、基于Pytorch的矩阵分解"><a href="#四、基于Pytorch的矩阵分解" class="headerlink" title="四、基于Pytorch的矩阵分解"></a>四、基于Pytorch的矩阵分解</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Bias-SVD代码实现</span></span><br><span class="line"><span class="comment"># 基于MovieLens 1M数据集</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> moviesData <span class="keyword">import</span> readRatings</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset, DataLoader</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MFDataset</span>(<span class="params">Dataset</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, u_id, i_id, rating</span>):</span></span><br><span class="line">        self.u_id = u_id</span><br><span class="line">        self.i_id = i_id</span><br><span class="line">        self.rating = rating</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span>(<span class="params">self, index</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self.u_id[index], self.i_id[index], self.rating[index]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.rating)</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MF</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, num_users, num_items, mean, embedding_size=<span class="number">100</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.user_emb = nn.Embedding(num_users, embedding_size) <span class="comment"># 隐向量</span></span><br><span class="line">        self.user_bias = nn.Embedding(num_users, <span class="number">1</span>)  <span class="comment"># 用户偏置</span></span><br><span class="line">        self.item_emb = nn.Embedding(num_items, embedding_size) <span class="comment"># 隐向量</span></span><br><span class="line">        self.item_bias = nn.Embedding(num_items, <span class="number">1</span>)  <span class="comment"># 物品偏置</span></span><br><span class="line">		</span><br><span class="line">        <span class="comment"># 参数初始化</span></span><br><span class="line">        self.user_emb.weight.data.uniform_(<span class="number">0</span>, <span class="number">0.005</span>)  <span class="comment"># 0-0.05之间均匀分布</span></span><br><span class="line">        self.user_bias.weight.data.uniform_(-<span class="number">0.01</span>, <span class="number">0.01</span>)</span><br><span class="line">        self.item_emb.weight.data.uniform_(<span class="number">0</span>, <span class="number">0.005</span>)</span><br><span class="line">        self.item_bias.weight.data.uniform_(-<span class="number">0.01</span>, <span class="number">0.01</span>)</span><br><span class="line">		</span><br><span class="line">        <span class="comment"># 全局偏置</span></span><br><span class="line">        <span class="comment"># 将不可训练的tensor转换成可训练的类型parameter，并绑定到module里，net.parameter()中就有了这个参数</span></span><br><span class="line">        self.mean = nn.Parameter(torch.FloatTensor([mean]), <span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, u_id, i_id</span>):</span></span><br><span class="line">        U = self.user_emb(u_id)</span><br><span class="line">        b_u = self.user_bias(u_id).squeeze()</span><br><span class="line">        I = self.item_emb(i_id)</span><br><span class="line">        b_i = self.item_bias(i_id).squeeze()</span><br><span class="line">        <span class="keyword">return</span> (U * I).<span class="built_in">sum</span>(<span class="number">1</span>) + b_u + b_i + self.mean <span class="comment"># 返回预测评分</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span>(<span class="params">model, x_train, y_train, loss_func</span>):</span></span><br><span class="line">    train_ls = [] <span class="comment"># 返回训练误差</span></span><br><span class="line">    train_dataset = MFDataset(x_train[:, <span class="number">0</span>], x_train[:, <span class="number">1</span>], y_train)</span><br><span class="line">    <span class="comment"># DataLoader将一个batch_size封装成一个tensor，方便迭代</span></span><br><span class="line">    train_iter = DataLoader(train_dataset, batch_size=<span class="number">1024</span>)</span><br><span class="line">	</span><br><span class="line">    <span class="comment"># weight_decay是正则化系数</span></span><br><span class="line">    optimizer = torch.optim.Adam(model.parameters(), lr=<span class="number">1e-4</span>, weight_decay=<span class="number">0.1</span>)</span><br><span class="line">    model = model.<span class="built_in">float</span>()</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">50</span>):</span><br><span class="line">        model.train()  <span class="comment"># 如果模型中有Batch Normalization或Dropout层，需要在训练时添加model.train()，使起作用</span></span><br><span class="line">        total_loss, total_len = <span class="number">0.0</span>, <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> x_u, x_i, y <span class="keyword">in</span> train_iter:</span><br><span class="line">            y_pred = model(x_u, x_i)</span><br><span class="line">            l = loss_func(y_pred, y).<span class="built_in">sum</span>()</span><br><span class="line">            optimizer.zero_grad() <span class="comment"># 清空这一批的梯度</span></span><br><span class="line">            l.backward() <span class="comment"># 回传</span></span><br><span class="line">            optimizer.step() <span class="comment"># 参数更新</span></span><br><span class="line"></span><br><span class="line">            total_loss += l.item()</span><br><span class="line">            total_len += <span class="built_in">len</span>(y)</span><br><span class="line">        train_ls.append(total_loss / total_len)</span><br><span class="line">    <span class="keyword">return</span> train_ls</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    pd.set_option(<span class="string">&#x27;display.max_rows&#x27;</span>, <span class="number">1000</span>, <span class="string">&#x27;display.max_columns&#x27;</span>, <span class="literal">None</span>,</span><br><span class="line">                  <span class="string">&#x27;display.float_format&#x27;</span>, <span class="keyword">lambda</span> x:<span class="string">&quot;%.2f&quot;</span> % x)</span><br><span class="line">    path = <span class="string">r&#x27;C:\Users\QzmVc1\Desktop\MovieLens&#x27;</span></span><br><span class="line">    df = readRatings(path)</span><br><span class="line"></span><br><span class="line">    x, y = df.iloc[:, :<span class="number">2</span>], df.iloc[:, <span class="number">2</span>]</span><br><span class="line">    x = torch.tensor(x.values, dtype=torch.int64)</span><br><span class="line">    y = torch.tensor(y.values, dtype=torch.float32)</span><br><span class="line"></span><br><span class="line">    x_train, x_test, y_train, y_test = train_test_split(x.numpy(), y.numpy(), test_size=<span class="number">0.3</span>, random_state=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    mean_rating = df.iloc[:, <span class="number">2</span>].mean()</span><br><span class="line">    <span class="comment"># 虽然数据集的UserID是从1开始的，但这里还是需要+1，因为nn.Embedding是从索引0开始，而model(x_u, x_i)传的是真实的ID</span></span><br><span class="line">    num_users, num_items = df[<span class="string">&#x27;UserID&#x27;</span>].<span class="built_in">max</span>()+<span class="number">1</span>, df[<span class="string">&#x27;MovieID&#x27;</span>].<span class="built_in">max</span>()+<span class="number">1</span></span><br><span class="line"></span><br><span class="line">    model = MF(num_users, num_items, mean_rating)</span><br><span class="line">    loss = nn.MSELoss(reduction=<span class="string">&#x27;sum&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    train_ls = train(model, x_train, y_train, loss)</span><br><span class="line">    <span class="built_in">print</span>(train_ls)</span><br></pre></td></tr></table></figure>


    </div>

    
    
    

    <footer class="post-footer">
          <div class="reward-container">
  <div>觉得本文对你有用的话，不妨打个赏吧~</div>
  <button>
    赞赏
  </button>
  <div class="post-reward">
      <div>
        <img src="/images/wechatpay.jpg" alt="QzmVc1 微信">
        <span>微信</span>
      </div>
      <div>
        <img src="/images/alipay.jpg" alt="QzmVc1 支付宝">
        <span>支付宝</span>
      </div>

  </div>
</div>

          

<div class="post-copyright">
<ul>
  <li class="post-copyright-author">
      <strong>本文作者： </strong>QzmVc1
  </li>
  <li class="post-copyright-link">
      <strong>本文链接：</strong>
      <a href="http://qzmvc1.top/%E6%88%91%E7%9A%84%E6%8E%A8%E8%8D%90%E7%AE%97%E6%B3%95%E4%B9%8B%E8%B7%AF-2-%E7%9F%A9%E9%98%B5%E5%88%86%E8%A7%A3.html" title="我的推荐算法之路(2):矩阵分解">http://qzmvc1.top/我的推荐算法之路-2-矩阵分解.html</a>
  </li>
  <li class="post-copyright-license">
    <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="noopener" target="_blank"><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！
  </li>
</ul>
</div>

          <div class="post-tags">
              <a href="/tags/%E6%8E%A8%E8%8D%90%E7%AE%97%E6%B3%95/" rel="tag"><i class="fa fa-tag"></i> 推荐算法</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/%E6%88%91%E7%9A%84%E6%8E%A8%E8%8D%90%E7%AE%97%E6%B3%95%E4%B9%8B%E8%B7%AF-1-%E5%8D%8F%E5%90%8C%E8%BF%87%E6%BB%A4.html" rel="prev" title="我的推荐算法之路(1):协同过滤">
                  <i class="fa fa-chevron-left"></i> 我的推荐算法之路(1):协同过滤
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/%E6%88%91%E7%9A%84%E6%8E%A8%E8%8D%90%E7%AE%97%E6%B3%95%E4%B9%8B%E8%B7%AF-3-%E4%BB%8EFM%E5%88%B0FFM.html" rel="next" title="我的推荐算法之路(3):从FM到FFM">
                  我的推荐算法之路(3):从FM到FFM <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>







  <div class="comments" id="comments">
    <script src="https://utteranc.es/client.js"
        repo="QzmVc1/blog-comment"
        issue-term="pathname"
        theme="github-light"
        crossorigin="anonymous"
        async>
    </script>
    <div class="comments utterances-container"></div>
</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">QzmVc1</span>
</div>
<div class="wordcount">
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-line"></i>
    </span>
      <span>站点总字数：</span>
    <span title="站点总字数">353k</span>
  </span>
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
      <span>站点阅读时长 &asymp;</span>
    <span title="站点阅读时长">5:21</span>
  </span>
</div>


<div class="busuanzi-count">
    <span class="post-meta-item" id="busuanzi_container_site_uv">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-item" id="busuanzi_container_site_pv">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>



<!--
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动
  </div>-->



    </div>
  </footer>

  
  <script src="https://cdn.jsdelivr.net/npm/animejs@3.2.1/lib/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/next-boot.js"></script><script src="/js/bookmark.js"></script>

  
<script src="https://cdn.jsdelivr.net/npm/hexo-generator-searchdb@1.4.0/dist/search.js" integrity="sha256-vXZMYLEqsROAXkEw93GGIvaB2ab+QW6w3+1ahD9nXXA=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>




  <script src="/js/third-party/pace.js"></script>

  
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js","integrity":"sha256-r+3itOMtGGjap0x+10hu6jW/gZCzxHsoKrOd7gyRSGY="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>




  <script async src="/js/cursor/fireworks.js"></script>

  
 
	<script type="text/javascript" src="//cdn.bootcss.com/canvas-nest.js/1.0.0/canvas-nest.min.js"></script>
 

<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"log":false,"model":{"jsonPath":"/live2dw/assets/hijiki.model.json"},"display":{"position":"right","width":150,"height":300},"mobile":{"show":true}});</script></body>
</html>

